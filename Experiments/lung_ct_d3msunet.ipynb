{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lung_ct_d3msunet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3tHgK8CNwXME","outputId":"ea27d813-8b34-41e9-b365-0f088d5a6ba6"},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"bYGsy-mh_F75"},"source":["from collections import OrderedDict\n","from torch import Tensor\n","import re\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.checkpoint as cp\n","from collections import OrderedDict\n","from torch import Tensor\n","from typing import Type, Any, Callable, Union, List, Optional\n","import glob\n","import os\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset\n","from torch import optim\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.utils.data import Subset,DataLoader\n","import torchvision.transforms as transforms\n","import torchvision\n","import random\n","from google.colab import files\n","from sklearn.metrics import  confusion_matrix\n","from sklearn.model_selection import ShuffleSplit\n","import cv2\n","from google.colab.patches import cv2_imshow\n","from scipy.ndimage import distance_transform_edt\n","from torch.autograd import Variable\n","import skimage.segmentation\n","import skimage.io\n","import skimage \n","from scipy.optimize import linear_sum_assignment\n","import skimage.segmentation\n","import matplotlib.pyplot as plt\n","import skimage.io\n","import skimage.segmentation\n","from skimage import feature\n","from skimage import filters\n","import copy\n","import torchvision\n","from collections import OrderedDict\n","import math\n","import imageio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7NnHYU9nAEcF"},"source":["def randomHueSaturationValue(\n","    image,\n","    hue_shift_limit=(-40, 40),\n","    sat_shift_limit=(-10, 10),\n","    val_shift_limit=(-20, 20),\n","    u=0.5,\n","):\n","    if np.random.random() < u:\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","        h, s, v = cv2.split(image)\n","        hue_shift = np.random.randint(\n","            hue_shift_limit[0], hue_shift_limit[1] + 1)\n","        hue_shift = np.uint8(hue_shift)\n","        h += hue_shift\n","        sat_shift = np.random.uniform(sat_shift_limit[0], sat_shift_limit[1])\n","        s = cv2.add(s, sat_shift)\n","        val_shift = np.random.uniform(val_shift_limit[0], val_shift_limit[1])\n","        v = cv2.add(v, val_shift)\n","        image = cv2.merge((h, s, v))\n","        image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)\n"," \n","    return image\n"," \n"," \n","def randomShiftScaleRotate(\n","    image,\n","    mask,\n","    shift_limit=(-0.1, 0.1),\n","    scale_limit=(-0.1, 0.1),\n","    aspect_limit=(-0.1, 0.1),\n","    rotate_limit=(-90, 90),\n","    borderMode=cv2.BORDER_CONSTANT,\n","    u=0.5,\n","):\n","    if np.random.random() < u:\n","        height, width, channel = image.shape\n"," \n","        angle = np.random.uniform(rotate_limit[0], rotate_limit[1])\n","        scale = np.random.uniform(1 + scale_limit[0], 1 + scale_limit[1])\n","        aspect = np.random.uniform(1 + aspect_limit[0], 1 + aspect_limit[1])\n","        sx = scale * aspect / (aspect ** 0.5)\n","        sy = scale / (aspect ** 0.5)\n","        dx = round(np.random.uniform(shift_limit[0], shift_limit[1]) * width)\n","        dy = round(np.random.uniform(shift_limit[0], shift_limit[1]) * height)\n"," \n","        cc = np.math.cos(angle / 180 * np.math.pi) * sx\n","        ss = np.math.sin(angle / 180 * np.math.pi) * sy\n","        rotate_matrix = np.array([[cc, -ss], [ss, cc]])\n"," \n","        box0 = np.array([[0, 0], [width, 0], [width, height], [0, height]])\n","        box1 = box0 - np.array([width / 2, height / 2])\n","        box1 = np.dot(box1, rotate_matrix.T) + np.array(\n","            [width / 2 + dx, height / 2 + dy]\n","        )\n"," \n","        box0 = box0.astype(np.float32)\n","        box1 = box1.astype(np.float32)\n","        mat = cv2.getPerspectiveTransform(box0, box1)\n","        image = cv2.warpPerspective(\n","            image,\n","            mat,\n","            (width, height),\n","            flags=cv2.INTER_NEAREST,\n","            borderMode=borderMode,\n","            borderValue=(0, 0, 0),\n","        )\n","        mask = cv2.warpPerspective(\n","            mask,\n","            mat,\n","            (width, height),\n","            flags=cv2.INTER_NEAREST,\n","            borderMode=borderMode,\n","            borderValue=(0, 0, 0),\n","        )\n"," \n","    return image, mask\n"," \n"," \n","def randomHorizontalFlip(image, mask, u=0.5):\n","    if np.random.random() < u:\n","        image = cv2.flip(image, 1)\n","        mask = cv2.flip(mask, 1)\n"," \n","    return image, mask\n"," \n"," \n","def randomVerticleFlip(image, mask, u=0.5):\n","    if np.random.random() < u:\n","        image = cv2.flip(image, 0)\n","        mask = cv2.flip(mask, 0)\n"," \n","    return image, mask\n"," \n"," \n","def randomRotate90(image, mask, u=0.5):\n","    if np.random.random() < u:\n","        image = np.rot90(image)\n","        mask = np.rot90(mask)\n"," \n","    return image, mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rxr6p3dtbiXO"},"source":["def hflip(image,mask):\n","  image=cv2.flip(image,0)\n","  mask=cv2.flip(mask,0)\n","  return image, mask\n","\n","def vflip(image,mask):\n","  image=cv2.flip(image,1)\n","  mask=cv2.flip(mask,1)\n","  return image, mask\n","\n","def diag(image,mask):\n","  image=image.T\n","  mask=mask.T\n","  return image,mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6fbA_Pguehdf"},"source":["image_files=glob.glob('/content/drive/MyDrive/Lung on ct dataset/2d_images*/**.tif')\n","image_files.sort()\n","mask_files=glob.glob('/content/drive/MyDrive/Lung on ct dataset/2d_masks*/**.tif')\n","mask_files.sort()\n","\n","len_data = len(image_files)\n","train_size = 0.8\n","\n","# example fold\n","\n","train_image_files=image_files[:int(len_data*train_size)]\n","train_mask_files=mask_files[:int(len_data*train_size)]\n","\n","test_image_files=image_files[int(len_data*train_size):]\n","test_mask_files=mask_files[int(len_data*train_size):]\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvSSNAEbAeCh"},"source":["class data_train(Dataset):\n","  def __init__(self,image,mask):\n","    self.image_path=image\n","    self.labels=mask\n","\n","  def __len__(self):\n","    return len(self.labels)\n","  def __getitem__(self, idx):\n","    image=imageio.imread(self.image_path[idx])\n","    mask=cv2.imread(self.labels[idx])\n","    mask=mask[:,:,0]\n","    image,mask=randomVerticleFlip(image,mask)\n","    image,mask=randomHorizontalFlip(image,mask)\n","    image,mask=randomRotate90(image,mask) \n","    image=torch.from_numpy(image*1.0).unsqueeze(0)#.permute(2,0,1)\n","    mask=torch.from_numpy(mask/255.0).unsqueeze(0)\n","    return image[0:1,:,:], mask \n"," \n","    \n","train_ds=data_train(train_image_files,train_mask_files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUSzAlNmMrze"},"source":["class data_test(Dataset):\n","  def __init__(self,image,mask):\n","    self.image_path=image\n","    self.labels=mask\n","    \n","  def __len__(self):\n","    return len(self.labels)\n","  def __getitem__(self, idx):\n","    image=imageio.imread(self.image_path[idx])\n","    mask=cv2.imread(self.labels[idx])\n","    mask=mask[:,:,0]\n","    image,mask=hflip(image,mask)\n","    image,mask=vflip(image,mask)\n","    image=torch.from_numpy(image*1.0).unsqueeze(0)\n","    mask=torch.from_numpy(mask/255.0).unsqueeze(0)\n","    \n","    return image[0:1,:,:], mask \n","    \n","test_ds=data_test(test_image_files,test_mask_files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BT9SSwQQcwuz"},"source":["train_dl = torch.utils.data.DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2)\n","test_dl = torch.utils.data.DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fk5nkC_2aJxV"},"source":["class Upsample(nn.Module):\n","    \"\"\" nn.Upsample is deprecated \"\"\"\n"," \n","    def __init__(self, scale_factor, mode=\"bilinear\"):\n","        super(Upsample, self).__init__()\n","        self.scale_factor = scale_factor\n","        self.mode = mode\n"," \n","    def forward(self, x):\n","        x = F.interpolate(x, scale_factor=self.scale_factor, mode=self.mode, align_corners=True, recompute_scale_factor=True)\n","        return x    \n","        \n","def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n"," \n"," \n","def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n"," \n"," \n","class BasicBlock(nn.Module):\n","    expansion: int = 1\n"," \n","    def __init__(\n","        self,\n","        inplanes: int,\n","        planes: int,\n","        stride: int = 1,\n","        downsample = True,\n","        groups: int = 1,\n","        base_width: int = 64,\n","        dilation: int = 1,\n","        norm_layer: Optional[Callable[..., nn.Module]] = None\n","    ) -> None:\n","        super(BasicBlock, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        if groups != 1 or base_width != 64:\n","            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n","        self.conv1 = conv3x3(inplanes, planes, stride,dilation=dilation)\n","        self.bn1 = norm_layer(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes,stride=1,dilation=dilation)\n","        self.bn2 = norm_layer(planes)\n","        if downsample == True:\n","            self.downsample = nn.Sequential(\n","                nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes),\n","            )\n","        elif isinstance(downsample, nn.Module):\n","            self.downsample = downsample\n","        else:\n","            self.downsample = None\n","        self.stride = stride\n"," \n","    def forward(self, x: Tensor) -> Tensor:\n","        identity = x\n"," \n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n"," \n","        out = self.conv2(out)\n","        out = self.bn2(out)\n"," \n","        if self.downsample is not None:\n","            identity = self.downsample(identity)\n"," \n","        out += identity\n","        out = self.relu(out)\n"," \n","        return out\n"," \n"," \n","class BasicBlock_2(nn.Module):\n","    expansion: int = 1\n"," \n","    def __init__(\n","        self,\n","        inplanes: int,\n","        planes: int,\n","        stride: int = 1,\n","        downsample: Optional[nn.Module] = None,\n","        groups: int = 1,\n","        base_width: int = 64,\n","        dilation: int = 1,\n","        norm_layer: Optional[Callable[..., nn.Module]] = None\n","    ) -> None:\n","        super(BasicBlock_2, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        if groups != 1 or base_width != 64:\n","            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n","        if dilation > 1:\n","            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = norm_layer(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n"," \n","    def forward(self, x: Tensor) -> Tensor:\n"," \n"," \n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n"," \n","        out = self.conv2(out)\n","        out = self.bn2(out)\n"," \n","        \n","        out = self.relu(out)\n"," \n","        return out\n"," \n"," \n","class ResNet(nn.Module):\n"," \n","    def __init__(\n","        self,\n","        initial_channel: int, \n","        block: Type[Union[BasicBlock, BasicBlock_2]],\n","        layers: List[int],\n","        num_classes: int = 1000,\n","        zero_init_residual: bool = False,\n","        groups: int = 1,\n","        width_per_group: int = 64,\n","        replace_stride_with_dilation: Optional[List[bool]] = None,\n","        norm_layer: Optional[Callable[..., nn.Module]] = None\n","    ) -> None:\n","        super(ResNet, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        self._norm_layer = norm_layer\n"," \n","        self.inplanes = 64\n","        self.dilation = 1\n","        if replace_stride_with_dilation is None:\n","            replace_stride_with_dilation = [False, False, False]\n","        if len(replace_stride_with_dilation) != 3:\n","            raise ValueError(\"replace_stride_with_dilation should be None \"\n","                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n","        self.groups = groups\n","        self.base_width = width_per_group\n","        self.conv1 = nn.Conv2d(initial_channel, self.inplanes, kernel_size=3, stride=1, padding=1,\n","                               bias=False)\n","        self.bn1 = norm_layer(self.inplanes)\n","        self.relu = nn.ReLU(inplace=True)\n"," \n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=1,\n","                                       dilate=False,dilation=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=1,\n","                                       dilate=False,dilation=4)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n","                                       dilate=False,dilation=8)\n"," \n","        self.maxpool1=nn.MaxPool2d(kernel_size=2,stride=2)\n","        self.maxpool2=nn.MaxPool2d(kernel_size=2,stride=2)\n","        self.maxpool3=nn.MaxPool2d(kernel_size=2,stride=2)\n","        self.maxpool4=nn.MaxPool2d(kernel_size=2,stride=2)\n"," \n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, Bottleneck):\n","                    nn.init.constant_(m.bn3.weight, 0)\n","                elif isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n"," \n","    def _make_layer(self, block: Type[Union[BasicBlock, BasicBlock_2]], planes: int, blocks: int,\n","                    stride: int = 1, dilate: bool = False,dilation: int = 1) -> nn.Sequential:\n","        norm_layer = self._norm_layer\n","        downsample = None\n","        previous_dilation = self.dilation\n","        if dilate:\n","            self.dilation *= stride\n","            stride = 1\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                norm_layer(planes * block.expansion),\n","            )\n"," \n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n","                            self.base_width, dilation, norm_layer))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes,stride=1,groups=self.groups,\n","                                base_width=self.base_width,dilation=dilation,\n","                                norm_layer=norm_layer))\n"," \n","        return nn.Sequential(*layers)\n"," \n","    def forward(self, x): \n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        \n","        x1 = self.layer1(x)\n","        x2 = self.layer2(self.maxpool1(x1))\n","        x3 = self.layer3(self.maxpool2(x2))\n","        x4 = self.layer4(self.maxpool3(x3))\n","        x5 = self.maxpool4(x4)\n"," \n","        return x1,x2,x3,x4,x5\n","\n"," \n","class bn_conv(nn.Module):\n","    def __init__(self,num_init_features,output_channels,dilation=1):\n","        super(bn_conv,self).__init__()\n","        self.features = nn.Sequential(OrderedDict([ \n","            ('conv0', nn.Conv2d(num_init_features,output_channels,kernel_size=3, stride=1,\n","                                padding=dilation, bias=False,dilation=dilation)), \n","            ('norm0', nn.BatchNorm2d(output_channels)),\n","            ('relu0', nn.ReLU(inplace=True))          \n","        ]))\n","    def forward(self,x):\n","        x=self.features(x)\n","        return x\n","\n","class bn_conv2(nn.Module):\n","    def __init__(self, initial_channels,output_channels,dilation=1):\n","        super(bn_conv2,self).__init__()\n","        self.conv1=bn_conv(initial_channels,output_channels,dilation)\n","        self.conv2=bn_conv(output_channels,output_channels,dilation)\n","    def forward(self, x):\n","        x=self.conv1(x)\n","        x=self.conv2(x)\n","        return x \n","\n","class up_conv(nn.Module):\n","    def __init__(self,initial_channels,output_channels,dilation):\n","        super(up_conv,self).__init__()\n","        self.upsample=Upsample(2)\n","        self.conv=bn_conv(initial_channels,output_channels,dilation)\n","    def forward(self,x):\n","        x=self.conv(self.upsample(x))\n","        return x\n","\n","class conv_11(nn.Module):\n","    def __init__(self,input_channels,output_channels):\n","        super(conv_11,self).__init__()\n","        self.conv=nn.Conv2d(input_channels,output_channels,kernel_size=1,stride=1)\n","    def forward(self,x):\n","        x=self.conv(x)\n","        return x\n","        \n","class decoder(nn.Module):\n","    def __init__(self,input_channels,upsample_factor,dilation):\n","        super(decoder,self).__init__()\n","        self.conv1=bn_conv(input_channels,input_channels//2,dilation)\n","        self.conv2=bn_conv(input_channels//2,input_channels//4,dilation)\n","        #Multi-Scale-Supervision-Block  \n","        self.conv3=nn.Conv2d(input_channels//4,64,kernel_size=3,stride=1,padding=1)\n","        self.conv4=conv_11(64,1)\n","        self.upsample=Upsample(upsample_factor)\n","        #End Multi-Scale_Supervision-Block\n","    def forward(self,x):\n","        x=self.conv1(x)\n","        x1=self.conv2(x)\n","        #Use of Multi-Scale-Supervision-Block\n","        x2=self.conv3(x1)    \n","        x2=self.conv4(self.upsample(x2))\n","        return x1,x2\n","\n","class final_decoder(nn.Module):\n","    def __init__(self,input_channels,dilation):\n","        super(final_decoder,self).__init__()\n","        self.conv1=bn_conv(input_channels,input_channels//2,dilation)\n","        self.conv2=nn.Conv2d(input_channels//2,64,kernel_size=3,stride=1,padding=1)\n","        self.conv3=conv_11(64,1)\n","\n","    def forward(self,x):\n","        x=self.conv1(x)\n","        x=self.conv2(x)\n","        x=self.conv3(x)\n","        return x\n","\n","\n","class D3MSU(nn.Module):\n","    def __init__(self,input_channels):\n","        super(D3MSU,self).__init__()\n","        self.encoder=ResNet(input_channels,BasicBlock,[3,3,3,3])\n","        self.bn_conv0=bn_conv2(512,512,8)\n","\n","        self.decoder1=decoder(1024,8,8)\n","        self.decoder2=decoder(512,4,4)\n","        self.decoder3=decoder(256,2,2)\n","        self.decoder4=final_decoder(128,1)\n","\n","        self.upconv1=nn.ConvTranspose2d(512,512,kernel_size=2,stride=2)\n","        self.upconv2=nn.ConvTranspose2d(256,256,kernel_size=2,stride=2)\n","        self.upconv3=nn.ConvTranspose2d(128,128,kernel_size=2,stride=2)\n","        self.upconv4=nn.ConvTranspose2d(64,64,kernel_size=2,stride=2)\n","\n","\n","    def forward(self,x):\n","        \n","        x1,x2,x3,x4,x5=self.encoder(x)\n","        \n","        x5=self.bn_conv0(x5)        \n","\n","        x5=self.upconv1(x5)\n","        x_4,x_out4=self.decoder1(torch.cat((x5,x4),1))\n","\n","        x_4=self.upconv2(x_4)\n","        x_3,x_out3=self.decoder2(torch.cat((x_4,x3),1))\n","\n","        x_3=self.upconv3(x_3)\n","        x_2,x_out2=self.decoder3(torch.cat((x_3,x2),1))\n","\n","        x_2=self.upconv4(x_2)\n","        x_out1=self.decoder4(torch.cat((x_2,x1),1))\n","        \n","        \n","        return torch.sigmoid(x_out1), torch.sigmoid(x_out2), torch.sigmoid(x_out3), torch.sigmoid(x_out4)\n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5QOPyLC0aJys"},"source":["model=D3MSU(1)\n","model=model.to('cuda:0')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2oPrfDWaJ2X"},"source":["#loss function\n","class dice_bce_loss(nn.Module):\n","    def __init__(self, batch=True):\n","        super(dice_bce_loss, self).__init__()\n","        self.batch = batch\n","        self.bce_loss = nn.BCELoss()\n"," \n","    def soft_dice_coeff(self, y_true, y_pred):\n","        smooth = 1.0  # may change\n","        if self.batch:\n","            i = torch.sum(y_true**2)\n","            j = torch.sum(y_pred**2)\n","            intersection = torch.sum(y_true * y_pred)\n","        else:\n","            i = (y_true**2).sum(1).sum(1).sum(1)\n","            j = (y_pred**2).sum(1).sum(1).sum(1)\n","            intersection = (y_true * y_pred).sum(1).sum(1).sum(1)\n","        score = (2. * intersection + smooth) / (i + j + smooth)\n","        return score.mean()\n"," \n","    def soft_dice_loss(self, y_true, y_pred):\n","        loss = 1 - self.soft_dice_coeff(y_true, y_pred)\n","        return loss\n"," \n","    def __call__(self, y_true, y_pred):\n","        y_true=y_true*1.0\n","        a = self.bce_loss(y_pred, y_true)\n","        b = self.soft_dice_loss(y_true, y_pred)\n","        return a + b"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIH6f9jfaJ3p"},"source":["class EIoU(nn.Module):\n","    def __init__(self, threshold=0.5):\n","        super(EIoU, self).__init__()\n","        self.threshold = threshold\n"," \n","    def forward(self, target, input):\n","        eps = 1e-10\n","        input_ = (input > self.threshold).data.float()\n","        target_ = (target > self.threshold).data.float()\n"," \n","        intersection = torch.clamp(input_ * target_, 0, 1)\n","        union = torch.clamp(input_ + target_, 0, 1)\n"," \n","        if torch.mean(intersection).lt(eps):\n","            return torch.Tensor([0., 0., 0., 0.])\n","        else:\n","            acc = torch.mean((input_ == target_).data.float())\n","            iou = torch.mean(intersection) / torch.mean(union)\n","            recall = torch.mean(intersection) / torch.mean(target_)\n","            precision = torch.mean(intersection) / torch.mean(input_)\n","            return torch.Tensor([acc, recall, iou, 1.0-iou])\n","iou=EIoU()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Fg775FQaKEN"},"source":["def multiscale_loss(prediction1,prediction2,prediction3,prediction4,label):\n","    dice_loss=dice_bce_loss()\n","    loss1=dice_loss(prediction1,label)\n","    loss2=dice_loss(prediction2,label)\n","    loss3=dice_loss(prediction3,label)\n","    loss4=dice_loss(prediction4,label)\n","    loss=loss1+loss2+loss3+loss4\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpbcTeswaXb6"},"source":["def dice_coeff(y_true,y_pred,batch=True):\n","        smooth = 1e-8  # may change\n","        if batch:\n","            i = torch.sum(y_true)\n","            j = torch.sum(y_pred)\n","            intersection = torch.sum(y_true * y_pred)\n","        else:\n","            i = y_true.sum(1).sum(1).sum(1)\n","            j = y_pred.sum(1).sum(1).sum(1)\n","            intersection = (y_true * y_pred).sum(1).sum(1).sum(1)\n","        score = (2. * intersection + smooth) / (i + j + smooth)\n","        return score.mean()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxVanjTyaXda"},"source":["def train_one_epoch_d3msunet(model, train_dl, learn):\n","    opt = torch.optim.Adam(model.parameters(),lr=learn)\n","    running_loss_image=0.0\n","    metric_epoch=0.0\n","    dice_epoch=0.0\n","    model.train()\n","    for a,b in train_dl:\n","        a=a.float()\n","        label=b[:,0:1,:,:].float()        \n","        pred1,pred2,pred3,pred4=model(a.cuda())\n","        loss=multiscale_loss(pred1,pred2,pred3,pred4,label.cuda())\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","        running_loss_image += loss\n","        metric=iou(label.cuda(),pred1)\n","        dice = dice_coeff(label.cuda(),pred1)\n","        dice_epoch += dice \n","        metric_epoch += metric\n","    running_loss_image/=len(train_dl)\n","    metric_epoch /= len(train_dl)\n","    dice_epoch /= len(train_dl)\n","    return model, metric_epoch, dice_epoch, running_loss_image\n"," \n","\n","def validate_one_epoch_d3msunet(model, val_dl):\n","    running_loss_image=0.0\n","    metric_epoch=0.0\n","    dice_epoch=0.0 \n","   \n","    with torch.no_grad():\n","        model.eval()\n","        for a,b in val_dl:\n","            a=a.float()\n","            label=b[:,0:1,:,:].float()\n","            pred1,pred2,pred3,pred4=model(a.cuda())\n","            loss=multiscale_loss(pred1,pred2,pred3,pred4,label.cuda())\n","            running_loss_image += loss\n","            metric=iou(label.cuda(),pred1)\n","            dice = dice_coeff(label.cuda(),pred1)\n","            dice_epoch += dice \n","            metric_epoch += metric  \n","    running_loss_image/=len(val_dl)\n","    metric_epoch /= len(val_dl)\n","    dice_epoch /= len(val_dl)\n","    return metric_epoch, dice_epoch, running_loss_image\n"," \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zP9hsiZtaXhD"},"source":["def train_epoches_d3msunet(model,train_dl,test_dl,epoches,learn,path):\n","    max_accuracy=0.0\n","    for i in range(epoches):\n","        model,metric_train,dice_train,loss_train=train_one_epoch_d3msunet(model,train_dl,learn)\n","        metric_test,dice_test,loss_test=validate_one_epoch_d3msunet(model,test_dl)\n","        print('epoch finished' +\" \" + str(i+1))\n","        print(f'train_loss: {loss_train:.6f} train_metrics: {metric_train} dice_train:{dice_train}')\n","        print(f'test_loss: {loss_test:.6f} test_metrics: {metric_test} dice_test:{dice_test}')\n","        print()\n","        \n","        if metric_test[2]>max_accuracy:\n","            max_accuracy=metric_test[2]\n","            path_final=os.path.join(path,\n","                                    f\"epoch{i}_test_iou{metric_test[2]:.4f}_eiou{metric_test[3]:.4f}.pth\")\n","            torch.save(model.state_dict(), path_final)\n","        \n"],"execution_count":null,"outputs":[]}]}